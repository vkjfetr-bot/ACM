# ðŸ§  ACMnxt â€” Implementation Tasklist for Codex

### Objective

Rebuild the entire Asset Condition Monitoring (ACM) pipeline from scratch â€” optimized, modular, well-commented, and analysis-rich.
This next-gen version (**ACMnxt**) consolidates all learnings: faster pipeline, cleaner code, more interpretable analytics, and simple, insightful visualizations.
Add detailed documentation, copy the dummy data folder with FD Fan files for training and testing.

---

## ðŸ§© 0. Engineering Principles (Apply Everywhere)

* **Comment everything:**

  * Each module â†’ docstring with pipeline ASCII + dataflow.
  * Each function â†’ `Args/Returns/Raises` + brief purpose + example.
  * Inline comments every ~10 lines for intent and rationale.
* **Type safety:** Python 3.11+, full `mypy --strict` compliance.
* **Config-driven:** Pydantic for schemas, YAML configs for runtime.
* **Performance:** Vectorized ops, avoid pandas `.apply`, cache intermediate steps.
* **Determinism:** Global RNG seed, explicit timezone handling (UTC + IST logs).

---

## ðŸ“ 1. Repository Structure

```
acmnxt/
  core/       â† ML, features, scoring
  io/         â† loaders, writers, schemas
  vis/        â† charts, plots, timelines
  report/     â† html/md builders
  cli/        â† entrypoints (train, score, report)
  scripts/    â† PowerShell + bash wrappers
  conf/       â† default + equipment configs
  tests/      â† unit + golden image + e2e tests
  docs/       â† diagrams, glossary, pipeline map
```

**Deliverable:**
`make setup` installs env; `pytest -q` passes all tests.

---

## ðŸ§¾ 2. Data I/O & Schemas

* **Readers:** CSV/XLSX â†’ dataframe with datetime index (`Ts` or parse column).
* **Writers:** Parquet for intermediates, PNGs for plots, HTML/MD for reports.
* **Schemas (Pydantic):**

  * `RunConfig`: paths, resample rate, toggles for H1â€“H3.
  * `ScoreRow`: ts, score, per-hypothesis scores, regime id.
  * `Event`: id, start, end, duration, peak, score, top_tags.

âœ… Tests for missing columns, bad encodings, tz shifts.

---

## ðŸ§¹ 3. Data Cleaning & DQ

| Function                            | Purpose                                  |
| ----------------------------------- | ---------------------------------------- |
| `clean_time(df)`                    | sort, drop dupes, enforce monotonic Ts   |
| `resample_numeric(df, rule='1min')` | uniform sampling                         |
| `compute_dq(df)`                    | detect flatlines, spikes, dropouts, NaN% |

* Output: `dq.csv`, heatmap, ranked table of tag issues.
  âœ… Works even if some tags are missing (graceful fallback).

---

## ðŸ§  4. Tag Selection

* `select_tags(df, include, exclude, variance_floor, max_n)`
* Drops low-variance or redundant tags.
* Logs reasons for each exclusion.
  âœ… Stable output given seed.

---

## âš™ï¸ 5. Feature Engineering

* Rolling mean/std, Î” values, z-scores (multi-window).
* Frequency: Welch PSD bands, dominant freq, flatness.
* Context: lag features, AR(1) residuals.
  âœ… Feature matrix shape = input rows (NaN warmup masked, not dropped).

---

## ðŸ§© 6. Hypotheses (H-stack Ensemble)

| Hypothesis | Method                   | Output                 |
| ---------- | ------------------------ | ---------------------- |
| **H1**     | AR(1) residual z-score   | Fast trend anomaly     |
| **H2**     | PCA reconstruction error | Multivariate anomaly   |
| **H3**     | Embedding drift distance | Regime-shift detection |

Each returns score âˆˆ [0,1]. Any can be toggled off.
âœ… Ensemble continues if one fails.

---

## ðŸ§­ 7. Regimes & Masks

* **Regimes:** Auto-K KMeans with silhouette sweep; store labels.
* **Masks:** Maintenance, startup/shutdown, DQ-bad windows.
  âœ… No re-fit explosion; stable silhouette logs.

---

## ðŸ”® 8. Fusion & Eventization

1. Fuse scores â†’ weighted geometric mean of active hypotheses.
2. Peak detection using MAD-based threshold.
3. Merge close peaks â†’ â€œepisodes.â€
4. Compute per-event stats: duration, max score, top tags.

âœ… Events non-overlapping and chronologically sorted.

---

## ðŸ“Š 9. Visualization (Charts Only)

* **Timeline:** fused + H1/H2/H3 bands, regimes, masks (color strips).
* **Per-event:** event window + spectra snapshot + tag trend grid.
* **Sampled Data:** entire test span with anomaly/mask markers.

âœ… Save as PNG; test golden image hashes.

---

## ðŸ“‘ 10. Report (Simple HTML + Markdown)

Sections:

1. Run summary (config, timestamps)
2. Data quality table
3. Timeline plot
4. Top-N events table
5. Per-event visual panels
6. Glossary (AR1, PCA, Drift explained)

âœ… No fancy cards, just tables & charts.
âœ… Inline term explanations for non-technical users.

---

## âš™ï¸ 11. CLI & PowerShell

**Python CLI:**

```bash
acmnxt train --csv --equip --out-dir
acmnxt score --csv --equip --art-dir
acmnxt report --art-dir --equip
```

**PowerShell:**
`run_acmnxt.ps1` â†’ single run
`BatchRunACMnxt.ps1` â†’ iterate over all equipment

âœ… Colored step logs, clear timings, non-zero exit on failure.

---

## âš¡ 12. Performance Targets

| Step   | Target (100kÃ—20tags) |
| ------ | -------------------- |
| TRAIN  | â‰¤ 15 s               |
| SCORE  | â‰¤ 5 s                |
| REPORT | â‰¤ 3 s                |

Techniques:

* Cached PCA & regimes
* Avoid deep sklearn loops
* Optional numba in heavy paths

---

## ðŸ§© 13. Config Management

* YAML config: global defaults + equipment overrides.
* Threshold helper: auto-suggest anomaly cutoffs (quantile/MAD).
  âœ… Config edit = rerun without code change.

---

## ðŸ§± 14. Robustness & Errors

* Descriptive exceptions (missing tags, NaN floods).
* Continue on partial failures (disable 1H, others run).
  âœ… Unit tests for each failure mode.

---

## ðŸ§ª 15. Testing

| Type   | Coverage                                |
| ------ | --------------------------------------- |
| Unit   | IO, DQ, features, H1â€“H3, fusion, events |
| Golden | FD FAN, Gas Turbine fixture data        |
| E2E    | Full run â†’ report â†’ validation          |

âœ… All `pytest` green in CI.

---

## ðŸ“œ 16. Logging & Artifacts

* `acmnxt.log` â†’ JSONL with timings, tag counts, KMeans info, thresholds.
* `run.json` â†’ summary for external consumption.

---

## ðŸ“¦ 17. Packaging & Release

* Build via `pyproject.toml`.
* GitHub Actions: lint + tests + wheel.
* Version tagging, CHANGELOG.md.

---

## ðŸ“˜ 18. Documentation & Commenting Targets

| Scope    | Expected Comments                     |
| -------- | ------------------------------------- |
| Module   | 15+ lines docstring + pipeline sketch |
| Function | Full Google-style docstring           |
| Block    | Inline comments every 8â€“12 LOC        |

**Docs Site:**
`docs/` with pipeline diagram, glossary, and walkthrough of reference functions.

---

## ðŸš€ 19. Stretch Goals

* SHAP-lite explainability per event (top contributing tags).
* Temporal smoothing (teacherâ€“student consistency).
* Optional Kafka event sink.

---

## ðŸ§± File Breakdown

| Path                                     | Responsibility            |
| ---------------------------------------- | ------------------------- |
| `core/features.py`                       | `build_features(df, cfg)` |
| `core/h1_ar1.py`                         | `score_h1()`              |
| `core/h2_pca.py`                         | `fit_pca()`, `score_h2()` |
| `core/h3_drift.py`                       | `score_drift()`           |
| `core/regimes.py`                        | `fit_assign_regimes()`    |
| `core/masks.py`                          | `make_masks()`            |
| `core/fusion.py`                         | `fuse_scores()`           |
| `core/events.py`                         | `build_events()`          |
| `io/loaders.py`, `io/writers.py`         | Data IO                   |
| `report/build.py`                        | Markdown â†’ HTML           |
| `vis/timeline.py`, `vis/event_panels.py` | Visualization             |
| `cli/*.py`                               | Command-line scripts      |
| `scripts/run_acmnxt.ps1`                 | Orchestration             |
| `tests/e2e/test_pipeline.py`             | Integration test          |

---

## âœ… Acceptance Checklist

* Full E2E run produces:
  `dq.csv`, `features.parquet`, `scores.csv`, `events.csv`, PNGs, and HTML report.
* Timeline & per-event visuals verified.
* Any H* toggle works independently.
* PowerShell wrappers functional.
* Comment density & typing targets met.

---

**Goal:**

> ACMnxt must be reproducible, self-documented, and explainable.
> A new developer should understand each algorithm and visualization just by reading the comments.
