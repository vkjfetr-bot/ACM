# core/sql_client.py
# === ACM V5 SQL Edition ===
# File: core/sql_client.py
# Date: 2025-10-22
# Version: SQL-Wire v2 (pyodbc, fast_executemany, simple proc caller)
#
# Purpose:
# - Provide a tiny, reliable wrapper over pyodbc for:
#     * connect(): open a pooled connection to SQL Server
#     * cursor(): get a raw cursor (data_io uses this for executemany)
#     * call_proc(proc_name, params_dict): execute stored procedures with named params
# - No TVPs are required by your current data_io (executemany with regular INSERT).
#
# Config expected under cfg["sql"]:
#   {
#     "server": "YOUR_SQL_HOST\\INSTANCE or tcp:host,1433",
#     "database": "ACM",
#     "user": "sa",
#     "password": "*****",
#     "driver": "ODBC Driver 17 for SQL Server",   # or 18/SQL Server Native Client
#     "timeout": 30,
#     "trust_server_certificate": true,            # optional
#     "mars": false,                               # optional (MultipleActiveResultSets)
#     "autocommit": false                          # optional
#   }
#
from __future__ import annotations

import os
import re
from typing import Any, Callable, Dict, Optional, Tuple
from contextlib import contextmanager
import configparser
from pathlib import Path

try:
    import pyodbc
except Exception as e:
    raise SystemExit("pyodbc is required. Install with: pip install pyodbc") from e

# Import tracing support (optional)
try:
    from core.observability import Span
    OTEL_AVAILABLE = True
except ImportError:
    OTEL_AVAILABLE = False
    Span = None


class SQLClient:
    """
    SQL Server client with support for multiple database connections.
    
    Can connect to one of three databases:
    - 'acm': ACM application database (anomaly results, run logs)
    - 'xstudio_dow': Equipment metadata database
    - 'xstudio_historian': Time-series historian database
    
    Usage:
        # Single database (legacy mode)
        client = SQLClient(cfg).connect()
        
        # Multiple databases
        acm_client = SQLClient.from_ini('acm').connect()
        dow_client = SQLClient.from_ini('xstudio_dow').connect()
        historian_client = SQLClient.from_ini('xstudio_historian').connect()
    """
    
    def __init__(self, cfg: Dict[str, Any], db_section: str = "acm"):
        self.cfg = dict(cfg or {})
        self.db_section = db_section  # Track which DB section this client uses
        self.conn: Optional[pyodbc.Connection] = None
        # Load external INI if present (overrides YAML for credentials/server)
        self._maybe_load_ini()

    @classmethod
    def from_ini(cls, db_section: str = "acm") -> "SQLClient":
        """
        Create SQLClient from INI config file section.
        
        Args:
            db_section: One of 'acm', 'xstudio_dow', 'xstudio_historian'
        
        Returns:
            SQLClient instance configured for the specified database
        """
        ini_path = Path(__file__).resolve().parents[1] / "configs" / "sql_connection.ini"
        if not ini_path.exists():
            raise FileNotFoundError(f"Config file not found: {ini_path}")
        
        parser = configparser.ConfigParser()
        parser.read(ini_path, encoding="utf-8")
        
        if not parser.has_section(db_section):
            raise ValueError(
                f"Section [{db_section}] not found in {ini_path}. "
                f"Available: {list(parser.sections())}"
            )
        
        # Convert INI section to dict
        cfg = dict(parser[db_section])
        return cls(cfg, db_section=db_section)

    def _maybe_load_ini(self) -> None:
        """Load INI config for this db_section (overrides YAML)."""
        try:
            ini_path = Path(__file__).resolve().parents[1] / "configs" / "sql_connection.ini"
            if ini_path.exists():
                parser = configparser.ConfigParser()
                parser.read(ini_path, encoding="utf-8")
                
                # Try to load the specific db_section first, fallback to legacy 'sql' section
                section = self.db_section if parser.has_section(self.db_section) else "sql"
                
                if parser.has_section(section):
                    sec = parser[section]
                    # Only override if present in INI
                    for k_ini, k_cfg in [
                        ("server", "server"),
                        ("database", "database"),
                        ("user", "user"),
                        ("password", "password"),
                        ("driver", "driver"),
                        ("encrypt", "encrypt"),
                        ("trust_server_certificate", "trust_server_certificate"),
                        ("trusted_connection", "trusted_connection"),
                        ("timeout", "timeout"),
                        ("mars", "mars"),
                        ("autocommit", "autocommit"),
                    ]:
                        if k_ini in sec and sec[k_ini] != "":
                            self.cfg[k_cfg] = sec.get(k_ini)
        except Exception:
            # Non-fatal: ignore INI loading issues
            pass

    # ---------- connection ----------
    def _build_conn_str(self, include_database: bool = True) -> str:
        server = self.cfg.get("server") or os.getenv("ACM_SQL_SERVER", "")
        database = self.cfg.get("database") or os.getenv("ACM_SQL_DATABASE", "ACM")
        user = self.cfg.get("user") or os.getenv("ACM_SQL_USER", "")
        password = self.cfg.get("password") or os.getenv("ACM_SQL_PASSWORD", "")
        trusted_conn = str(self.cfg.get("trusted_connection", "no")).strip().lower() in ("1","true","yes","y")
        driver_cfg = self.cfg.get("driver") or os.getenv("ACM_SQL_DRIVER", "ODBC Driver 18 for SQL Server")
        # Choose an installed ODBC driver (fallback gracefully)
        try:
            available = [d.strip().lower() for d in pyodbc.drivers()]
        except Exception:
            available = []
        candidates = [driver_cfg, "ODBC Driver 18 for SQL Server", "ODBC Driver 17 for SQL Server", "SQL Server"]
        driver = None
        for cand in candidates:
            if cand and cand.strip().lower() in available:
                driver = cand
                break
        if not driver:
            # Use requested even if not detected; ODBC may still resolve it, but warn via environment
            driver = driver_cfg
        # normalize booleans and ints
        timeout = int(self.cfg.get("timeout") or self.cfg.get("timeout_seconds") or os.getenv("ACM_SQL_TIMEOUT", 30))
        trust = str(self.cfg.get("trust_server_certificate", "yes")).strip().lower() in ("1","true","yes","y")
        mars = str(self.cfg.get("mars", "no")).strip().lower() in ("1","true","yes","y")

        parts = [
            "DRIVER={%s}" % driver,
            f"SERVER={server}",
        ]
        
        # Windows Authentication vs SQL Server Authentication
        if trusted_conn:
            parts.append("Trusted_Connection=yes")
        else:
            parts.append(f"UID={user}")
            parts.append(f"PWD={password}")
        
        parts.append(f"Connection Timeout={timeout}")
        
        if include_database and database:
            parts.insert(2, f"DATABASE={database}")
        if trust:
            parts.append("TrustServerCertificate=yes")
        if mars:
            parts.append("MARS_Connection=yes")
        # If using Azure SQL or TLS, these flags are ok; leave others default.
        return ";".join(parts)

    def connect(self) -> "SQLClient":
        if self.conn is not None:
            return self
        autocommit = str(self.cfg.get("autocommit", "false")).strip().lower() in ("1","true","yes","y")
        # Try with database first
        try:
            conn_str = self._build_conn_str(include_database=True)
            self.conn = pyodbc.connect(conn_str, autocommit=autocommit)
        except Exception as e:
            s = str(e)
            # Fallback: connect without explicit database (e.g., ACM not created yet)
            if ("4060" in s) or ("Cannot open database" in s):
                conn_str2 = self._build_conn_str(include_database=False)
                self.conn = pyodbc.connect(conn_str2, autocommit=autocommit)
            else:
                raise
        # Conservative defaults; data_io toggles fast_executemany per cursor
        try:
            # lightweight keepalive
            self.conn.timeout = int(self.cfg.get("timeout", 30))
        except Exception:
            pass
        return self

    def close(self) -> None:
        if self.conn is not None:
            try:
                self.conn.close()
            finally:
                self.conn = None

    def commit(self) -> None:
        """Commit the current transaction. TASK-5-FIX: Expose commit() method on SQLClient."""
        if self.conn is not None and not self.conn.autocommit:
            self.conn.commit()

    def rollback(self) -> None:
        """Rollback the current transaction. TASK-5-FIX: Expose rollback() method on SQLClient."""
        if self.conn is not None and not self.conn.autocommit:
            self.conn.rollback()

    # ---------- basic primitives ----------
    def cursor(self) -> pyodbc.Cursor:
        if self.conn is None:
            raise RuntimeError("SQLClient.cursor() called before connect().")
        return self.conn.cursor()

    @contextmanager
    def get_cursor(self):
        """
        Context manager for cursor with automatic cleanup.
        
        Usage:
            with sql_client.get_cursor() as cur:
                cur.execute("SELECT ...")
                rows = cur.fetchall()
        """
        if self.conn is None:
            raise RuntimeError("SQLClient.get_cursor() called before connect().")
        cur = self.conn.cursor()
        try:
            yield cur
        finally:
            cur.close()

    # Simple proc invoker (without TVPs or OUTPUT capture).
    # Usage: call_proc("dbo.usp_ACM_FinalizeRun", {"RunID": "...", "Outcome": "OK", ...})
    def call_proc(self, proc_name: str, params: Optional[Dict[str, Any]] = None) -> Optional[int]:
        if self.conn is None:
            raise RuntimeError("SQLClient.call_proc() called before connect().")
        params = params or {}
        # Build "EXEC dbo.usp_X @A=?, @B=?, ..." with stable param order.
        names = list(params.keys())
        named = ", ".join([f"@{n} = ?" for n in names])
        tsql = f"EXEC {proc_name} {named}" if named else f"EXEC {proc_name}"
        cur = self.cursor()
        try:
            cur.execute(tsql, tuple(params[n] for n in names))
            # If proc returns a result set (rare here), consume first row count.
            try:
                _ = cur.fetchall()
            except Exception:
                pass
            # Commit for non-autocommit connections.
            if not self.conn.autocommit:
                self.conn.commit()
            # Return rows affected if available; pyodbc rowcount may be -1 depending on driver.
            return cur.rowcount if cur.rowcount is not None else None
        except Exception:
            if not self.conn.autocommit:
                self.conn.rollback()
            raise
        finally:
            cur.close()

    # Optional helpers if you ever need one-off SQL
    def execute(self, tsql: str, *args) -> int:
        """Execute a single T-SQL statement with optional span tracing."""
        # Extract table name and operation type for span attributes
        operation_type = "query"
        table_name = None
        if "INSERT" in tsql.upper():
            operation_type = "insert"
            match = re.search(r'INTO\s+(\w+)', tsql, re.IGNORECASE)
            if match:
                table_name = match.group(1)
        elif "UPDATE" in tsql.upper():
            operation_type = "update"
            match = re.search(r'UPDATE\s+(\w+)', tsql, re.IGNORECASE)
            if match:
                table_name = match.group(1)
        elif "DELETE" in tsql.upper():
            operation_type = "delete"
            match = re.search(r'FROM\s+(\w+)', tsql, re.IGNORECASE)
            if match:
                table_name = match.group(1)
        else:
            operation_type = "select"
            match = re.search(r'FROM\s+(\w+)', tsql, re.IGNORECASE)
            if match:
                table_name = match.group(1)
        
        # Use Span for tracing (optional, graceful fallback if not available)
        span_context = None
        if OTEL_AVAILABLE and Span is not None:
            span_context = Span(
                f"sql.execute",
                operation_type=operation_type,
                table=table_name or "unknown",
            )
            span_context.__enter__()
        
        try:
            cur = self.cursor()
            try:
                cur.execute(tsql, args)
                if not self.conn.autocommit:
                    self.conn.commit()
                rows_affected = cur.rowcount if cur.rowcount is not None else -1
                
                # Set span attributes for result
                if span_context is not None:
                    span_context._span.set_attribute("acm.rows_affected", rows_affected)
                
                return rows_affected
            except Exception:
                if not self.conn.autocommit:
                    self.conn.rollback()
                if span_context is not None:
                    span_context._span.set_attribute("acm.error", True)
                raise
            finally:
                cur.close()
        finally:
            if span_context is not None:
                span_context.__exit__(None, None, None)

    def executemany(self, tsql: str, seq_of_params) -> int:
        """Execute a batch of statements with optional span tracing."""
        # Extract table name for span attributes
        table_name = None
        if "INSERT" in tsql.upper():
            match = re.search(r'INTO\s+(\w+)', tsql, re.IGNORECASE)
            if match:
                table_name = match.group(1)
        
        # Use Span for tracing
        span_context = None
        if OTEL_AVAILABLE and Span is not None:
            span_context = Span(
                f"sql.executemany",
                operation_type="insert_batch",
                table=table_name or "unknown",
                batch_size=len(seq_of_params) if hasattr(seq_of_params, '__len__') else -1,
            )
            span_context.__enter__()
        
        try:
            cur = self.cursor()
            try:
                cur.fast_executemany = True
                cur.executemany(tsql, seq_of_params)
                if not self.conn.autocommit:
                    self.conn.commit()
                # len(seq_of_params) is generally a better inserted count than rowcount with ODBC
                try:
                    rows_affected = len(seq_of_params)
                except Exception:
                    rows_affected = cur.rowcount if cur.rowcount is not None else -1
                
                # Set span attributes for result
                if span_context is not None:
                    span_context._span.set_attribute("acm.rows_affected", rows_affected)
                
                return rows_affected
            except Exception:
                if not self.conn.autocommit:
                    self.conn.rollback()
                if span_context is not None:
                    span_context._span.set_attribute("acm.error", True)
                raise
            finally:
                cur.close()
        finally:
            if span_context is not None:
                span_context.__exit__(None, None, None)

    # ---------- ACM-specific methods ----------
    def get_equipment_id(self, equipment_name: str) -> int:
        """
        Convert equipment name to numeric ID from Equipment table.
        
        Args:
            equipment_name: Equipment code (e.g., 'FD_FAN', 'GAS_TURBINE')
        
        Returns:
            EquipID from Equipment table, or hash-based fallback (1-9999)
        """
        if not equipment_name:
            return 0
        
        # Query Equipment table for actual ID
        if self.conn is not None:
            try:
                with self.get_cursor() as cur:
                    cur.execute("SELECT EquipID FROM Equipment WHERE EquipCode = ?", (equipment_name,))
                    row = cur.fetchone()
                    if row:
                        return int(row[0])
            except Exception:
                pass  # Fall through to hash-based fallback
        
        # Fallback: Generate deterministic ID from equipment name (1-9999 range)
        import hashlib
        hash_val = int(hashlib.md5(equipment_name.encode()).hexdigest(), 16)
        equip_id = (hash_val % 9999) + 1  # Range: 1-9999
        return equip_id

    def start_run(
        self, 
        cfg: Dict[str, Any], 
        equip_code: str,
        deadlock_retry_func: Optional[Callable] = None
    ) -> Tuple[str, Any, Any, int]:
        """
        Start a run by inserting into ACM_Runs table.
        
        Args:
            cfg: Configuration dictionary (for tick_minutes, hash)
            equip_code: Equipment code string
            deadlock_retry_func: Function to execute SQL with deadlock retry
            
        Returns:
            Tuple of (run_id, window_start, window_end, equip_id)
        """
        import uuid
        import pandas as pd
        
        equip_id = self.get_equipment_id(equip_code)
        tick_minutes = cfg.get("runtime", {}).get("tick_minutes", 30)
        config_hash = cfg.get("hash", "")
        
        default_start = pd.Timestamp.utcnow() - pd.Timedelta(minutes=tick_minutes)
        
        # Generate RunID
        run_id = str(uuid.uuid4())
        window_start = default_start
        window_end = default_start + pd.Timedelta(minutes=tick_minutes)
        now = pd.Timestamp.utcnow()

        if self.conn is None:
            raise RuntimeError("SQLClient.start_run() called before connect().")
        
        # Use simple execute if no retry function provided
        if deadlock_retry_func is None:
            def deadlock_retry_func(cur, sql, params):
                cur.execute(sql, params)
            
        cur = self.cursor()
        try:
            # For idempotent re-runs, delete any prior run with same RunID
            deadlock_retry_func(cur, "DELETE FROM dbo.ACM_HealthForecast WHERE RunID = ?", (run_id,))
            deadlock_retry_func(cur, "DELETE FROM dbo.ACM_FailureForecast WHERE RunID = ?", (run_id,))
            deadlock_retry_func(cur, "DELETE FROM dbo.ACM_RUL WHERE RunID = ?", (run_id,))
            deadlock_retry_func(cur, "DELETE FROM dbo.ACM_Runs WHERE RunID = ?", (run_id,))
            
            # Direct INSERT into ACM_Runs
            deadlock_retry_func(
                cur,
                """
                SET QUOTED_IDENTIFIER ON;
                INSERT INTO dbo.ACM_Runs (RunID, EquipID, StartedAt, ConfigSignature)
                VALUES (?, ?, ?, ?)
                """,
                (run_id, equip_id, now, config_hash)
            )
            
            self.conn.commit()
            return run_id, window_start, window_end, equip_id
        except Exception:
            try:
                self.conn.rollback()
            except Exception:
                pass
            raise
        finally:
            cur.close()

    def finalize_run(
        self,
        run_id: str,
        outcome: str,
        rows_read: int,
        rows_written: int,
        err_json: Optional[str] = None,
    ) -> None:
        """
        Finalize a run by updating ACM_Runs with completion status.
        Uses direct SQL to bypass stored procedure QUOTED_IDENTIFIER issues.
        
        Args:
            run_id: The run UUID
            outcome: Status string (e.g., "SUCCESS", "NOOP", "ERROR")
            rows_read: Count of rows loaded from historian
            rows_written: Count of rows written to output tables
            err_json: Optional error message JSON
        """
        try:
            cur = self.cursor()
            try:
                cur.execute(
                    """
                    SET QUOTED_IDENTIFIER ON;
                    UPDATE dbo.ACM_Runs
                    SET CompletedAt = GETUTCDATE(),
                        TrainRowCount = COALESCE(?, TrainRowCount),
                        ScoreRowCount = COALESCE(?, ScoreRowCount),
                        ErrorMessage = COALESCE(?, ErrorMessage)
                    WHERE RunID = ?
                    """,
                    (rows_read, rows_written, err_json, run_id)
                )
                self.conn.commit()
            finally:
                cur.close()
        except Exception as e:
            # Environments may lack the table/columns; do not fail the pipeline
            pass


def execute_with_deadlock_retry(
    cur: Any,
    sql: str,
    params: tuple = (),
    max_retries: int = 3,
    delay: float = 0.5,
) -> None:
    """
    Execute SQL with automatic retry on deadlock (SQL Server error 1205).
    
    This is a module-level function that can be passed to start_run() or 
    used directly when executing statements that may conflict with other
    concurrent transactions.
    
    Args:
        cur: Database cursor
        sql: SQL statement to execute
        params: Parameters for the SQL statement
        max_retries: Maximum number of retry attempts
        delay: Base delay between retries (exponential backoff applied)
    """
    import time
    for attempt in range(max_retries):
        try:
            cur.execute(sql, params)
            return
        except Exception as e:
            err_str = str(e)
            # SQL Server deadlock error code 1205
            if "1205" in err_str or "deadlock" in err_str.lower():
                if attempt < max_retries - 1:
                    time.sleep(delay * (attempt + 1))  # Exponential backoff
                    continue
            raise
