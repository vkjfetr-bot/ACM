# Master ACM Backlog – Analytics & Forecasting Stack

| ID            | Priority | Module                                                             | Category                    | Area                                                                                                                                         | Issue (Observed)                                                                                                                                                                                                                                             | Action / Fix (For Copilot)                                                                                                                                                                                                                                                                                                                                    |
| ------------- | -------- | ------------------------------------------------------------------ | --------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ~~COR-01~~        | ~~High~~     | ~~`correlation.py`~~                                                   | ~~Correctness~~                 | ~~`MahalanobisDetector.fit`~~                                                                                                                    | ~~Uses full covariance + regularization but assumes `X.shape[0] ≥ 2`. For 0–1 row baselines (early cold-start / extreme filters), covariance is degenerate and behaviour is undefined.~~                                                                         | ~~At top of `fit`: if `X.shape[0] < 2`, set `self.mu = X.mean(axis=0)` (or zeros), `self.S_inv = np.eye(X.shape[1], dtype=np.float64)`, log a warning that Mahalanobis is in "identity fallback" due to insufficient samples. Keep normal path unchanged when `n ≥ 2`.~~ **COMPLETED**                                                                                          |
| ~~COR-02~~        | ~~High~~     | ~~`correlation.py`~~                                                   | ~~Correctness~~                 | ~~`PCASubspaceDetector.fit`~~                                                                                                                    | ~~After dropping NaN/constant columns, PCA is still attempted even if remaining `df.shape[0] < 2`, which under-determines PCA and may produce unstable components.~~                                                                                             | ~~At top of `fit`, after feature filtering: if `df.shape[0] < 2`, set `self.pca = None`, `self.keep_cols = []`, and ensure `score()` returns zeros (or NaN) consistently for this fallback. Log a warning. This is a guardrail, not new behaviour.~~ **COMPLETED**
| ~~ACM-CSV-01~~    | ~~High~~     | ~~`acm_main.py`~~                                                      | ~~SQL Migration~~               | ~~Baseline buffer~~                                                                                                                              | ~~In SQL mode, baseline is already maintained in `ACM_BaselineBuffer` via stored procs, but `acm_main` still reads/writes `baseline_buffer.csv`. Two parallel baselines can diverge.~~                                                                           | ~~For SQL mode: remove `baseline_buffer.csv` logic. Replace all reads/writes with SQL operations: read baseline history from `ACM_BaselineBuffer` (filtered by `EquipID`, time window) and append new SCORE rows there. Keep CSV baseline only behind explicit `if not SQL_MODE` for dev/file-mode.~~ **COMPLETED**                                                             |
| ~~ACM-CSV-02~~    | ~~Med~~      | ~~`acm_main.py`~~                                                      | ~~SQL Migration~~               | ~~Drop-log CSV~~                                                                                                                                 | ~~When features are dropped at runtime (e.g. all-NaN, zero variance), a local `drop_log.csv` is written. This is purely diagnostic and not in SQL.~~                                                                                                             | ~~Create an `ACM_FeatureDropLog` table (`RunID`, `EquipID`, `FeatureName`, `Reason`, `Timestamp`). Replace `drop_df.to_csv(...)` with `sql_client.insert_many(...)`. In SQL-only deployments, don't emit CSV; rely on the SQL log for debugging.~~ **COMPLETED**                                                                                                                                |
| ~~ACM-CSV-03~~    | ~~High~~     | ~~`acm_main.py`~~                                                      | ~~SQL Migration~~               | ~~Config auto-tune via `config_table.csv`~~                                                                                                      | ~~Auto-tune logic (clip_z, k_sigma, k_max) still writes back to `config_table.csv`, while SQL mode uses `ACM_Config` / `ACM_ConfigHistory` as real config store. Risk of config drift between CSV and SQL.~~                                                     | ~~Remove CSV updates in SQL mode. When tuning actions are generated, call SQL procs to: (1) insert to `ACM_ConfigHistory`, (2) update `ACM_Config` in-place for that `EquipID`. Only keep CSV-based config editing in explicit offline/file mode, not production.~~ **COMPLETED**                                                                                               |
| ~~ACM-CSV-04~~    | ~~Med~~      | ~~`acm_main.py`~~                                                      | ~~SQL Migration~~               | ~~Metrics CSV in `tables/`~~                                                                                                                     | ~~Some internal run metrics (fit times, detector stats) are written as CSV in `tables_dir`. Same info is more useful in SQL for Grafana.~~                                                                                                                       | ~~Add table `ACM_RunMetrics` (RunID, EquipID, MetricName, MetricValue, Timestamp). Replace `metrics_df.to_csv(...)` with SQL bulk insert. Use these metrics for monitoring dashboards instead of CSV.~~ **COMPLETED**                                                                                                                                                           |
| ~~OM-CSV-01~~     | ~~High~~     | ~~`output_manager.py`~~                                                | ~~SQL Migration~~               | ~~`_read_csv_with_peek`~~                                                                                                                        | ~~Helper for reading CSV files (train/score) with inferred timestamp col. In SQL mode it should never be used, but code paths still exist.~~                                                                                                                     | ~~Ensure SQL mode never passes file paths into `OutputManager`. For SQL mode, always pass DataFrames already loaded from SQL. Keep `_read_csv_with_peek` only behind explicit file-mode (`if not sql_only_mode`).~~ **COMPLETED**                                                                                                                                               |
| ~~OM-CSV-02~~     | ~~High~~     | ~~`output_manager.py`~~                                                | ~~SQL Migration~~               | ~~`df.to_csv(...)` in `write_*`~~                                                                                                                | ~~Many `write_*` methods (scores, drift, hotspots, data quality) write CSVs to `tables_dir`, even when `sql_only_mode=True`.~~                                                                                                                                   | ~~For SQL mode, enforce: if `sql_only_mode`, skip all `to_csv` calls. Confirm every CSV output has a SQL twin (`ACM_Scores_Wide`, `ACM_SensorHotspots`, `ACM_DriftTS`, `ACM_DataQuality`, etc.). In dev/file-mode you can still write CSV.~~ **COMPLETED**                                                                                                                      |
| ~~OM-CSV-03~~     | ~~High~~     | ~~`run_metadata_writer.py` + `output_manager.py`~~                     | ~~SQL Migration~~               | ~~`data_quality.csv`~~                                                                                                                           | ~~Data quality metrics are written to `data_quality.csv` and then read back in `run_metadata_writer`. This diverges from SQL and can break if CSV missing.~~                                                                                                     | ~~Change `OutputManager` to write data-quality rows to `ACM_DataQuality` (RunID, EquipID, metric fields). Update `extract_data_quality_score` to query `ACM_DataQuality` instead of reading CSV. Remove `data_quality_path` usage in production.~~ **COMPLETED**                                                                                                                |
| ~~REG-CSV-01~~    | ~~High~~     | ~~`regimes.py`~~                                                       | ~~SQL Migration~~               | ~~`_read_episodes_csv`, `_read_scores_csv`~~                                                                                                     | ~~Regime analysis uses CSV (`episodes.csv`, `scores.csv`) for file-mode analysis, with schemas that may drift from SQL.~~                                                                                                                                        | ~~Replace these with SQL readers: use `sql_client` to pull from `ACM_Episodes` and `ACM_Scores_Wide` by `EquipID`, `RunID`, time range. Keep function names but implement them as SQL queries; only allow CSV path in explicit offline/dev mode.~~ **COMPLETED**                                                                                                                |
| ~~REG-CSV-02~~    | ~~High~~     | ~~`regimes.py`~~                                                       | ~~SQL Migration~~               | ~~CSV outputs (`regime_episodes.csv`, summary, importance, transitions)~~                                                                        | ~~`run(ctx, ...)` writes multiple CSVs (episodes, summary, feature importance, transitions). Same artefacts should live in SQL.~~                                                                                                                                | ~~Add SQL tables: `ACM_RegimeEpisodes`, `ACM_RegimeSummary`, `ACM_RegimeFeatureImportance`, `ACM_RegimeTransitions`. Replace each `to_csv` with SQL inserts. For any later consumers (dashboards), query these tables instead of reading CSVs.~~ **COMPLETED**                                                                                                                  |
| ~~REG-CSV-03~~    | ~~Med~~      | ~~`regimes.py`~~                                                       | ~~SQL Migration~~               | ~~Plotting from CSV scores~~                                                                                                                     | ~~Plotting uses `scores.csv` and regime episodes for visual debugging.~~                                                                                                                                                                                         | ~~Move this plotting logic to a separate dev/debug script that reads from SQL (or an ad-hoc notebook). In `regimes.py`, do not load scores from CSV at all in SQL mode.~~ **COMPLETED**                                                                                                                                                                                         |
| ~~REG-COR-01~~    | ~~Med~~      | ~~`regimes.py` / `forecast_deprecated.py`~~                            | ~~Correctness / Duplication~~   | ~~`_to_datetime_mixed` duplicated in `regimes.py` and `forecast_deprecated.py`. If fixed in one location only, behaviour diverges.~~             | ~~Keep `_to_datetime_mixed` in a single module (e.g. `regimes` or a shared `utils`). Make all callers import from there. Remove duplicate copies in deprecated modules. This reduces risk of inconsistent datetime parsing.~~ **COMPLETED**                                    |                                                                                                                                                                                                                                                                                                                                                               |
| ~~REG-COR-02~~    | ~~Med~~      | ~~`regimes.py`~~                                                       | ~~Correctness~~                 | ~~`build_summary_dataframe`, `update_health_labels`~~                                                                                            | ~~Logic for regime health summary is correct, but currently tightly coupled to CSV outputs and not consistently persisted to SQL.~~                                                                                                                              | ~~Keep algorithms unchanged, but ensure their outputs are passed to `OutputManager` and written to `ACM_RegimeSummary` (SQL). Remove reliance on reading summary back from CSV. This is "move to SQL" not "change logic".~~ **COMPLETED**                                                                                                                                       |
| ~~FOR-CSV-01~~    | ~~Med~~      | ~~`forecast_deprecated.py`~~                                           | ~~SQL Migration~~               | ~~`_read_scores`, CSV loaders, legacy AR1 engine~~                                                                                               | ~~Legacy forecasting: reads score CSVs, runs AR1, writes CSV/plots. Main ACM pipeline now uses `forecasting.py`.~~                                                                                                                                               | ~~Identify any remaining imports of `forecast_deprecated`. For each, migrate to use `forecasting.py` on data from `ACM_Scores_Wide`. Once no live callers remain, you can retire the module without losing functionality.~~ **COMPLETED**                                                                                                                                       |
| FOR-CSV-02    | Med      | `enhanced_forecasting_deprecated.py`                               | SQL Migration               | `EnhancedForecastingEngine` file mode                                                                                                        | Reads health/scores from CSV and writes CSV outputs; acts as old “enhanced forecasting” wrapper.                                                                                                                                                             | For any features you still need: reimplement their logic in `forecasting.py` using SQL tables (`ACM_HealthTimeline`, `ACM_Scores_Wide`, `ACM_ForecastState`). Keep this module as legacy only; do not extend or use it in production.                                                                                                                         |
| ~~FOR-COR-01~~    | ~~High~~     | ~~`forecasting.py`~~                                                   | ~~Bug~~                         | ~~`legacy_forecast_section` (your audit §1.1)~~                                                                                                  | ~~At line ~557: `legacy_forecast_section.get("max_forecast_hours")` references an undefined variable; yields `NameError` if executed.~~                                                                                                                          | ~~Remove this line or replace with the correct config section (`cfg["forecasting"]["legacy"]` or similar). If the field is truly unused, simply delete the reference. Ensure unit test covers this path.~~ **COMPLETED**                                                                                                                                                        |
| ~~FOR-COR-02~~    | ~~High~~     | ~~`forecasting.py`~~                                                   | ~~Correctness~~                 | ~~RunID / EquipID type inconsistency (your §1.2)~~                                                                                               | ~~Places where `SourceRunID` and `RunID` are cast to `str` while `EquipID` is `int`, and SQL schema may expect consistent types. Mixed use may cause SQL insert failures or subtle bugs.~~                                                                       | ~~Decide on a canonical type: typically `RunID` as string/UUID, `EquipID` as int. Make sure every DataFrame destined for SQL uses this policy consistently (no ad-hoc `str(run_id)` vs `int(run_id)`). Align `OutputManager` SQL write functions to the same types.~~ **COMPLETED**                                                                                             |
| ~~FOR-COR-03~~    | ~~High~~     | ~~`forecasting.py`~~                                                   | ~~Bug~~                         | ~~Dangerous float cast in drift check (your §1.3)~~                                                                                              | ~~Code does: `avg_drift = float(row[0])` after a loose check. If `row` exists but `row[0]` is `None`, this raises.~~                                                                                                                                             | ~~Fix: `if row and row[0] is not None: avg_drift = float(row[0]); else: avg_drift = 0.0` or mark drift as "stable". This keeps intended behaviour and removes crash risk.~~ **COMPLETED**                                                                                                                                                                                       |
| ~~FOR-COR-04~~    | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Correctness~~                 | ~~`df_scores.set_index("Timestamp")` without dedupe (your §1.4)~~                                                                                | ~~If there are duplicate timestamps, `set_index` will either silently drop duplicates or produce ambiguous indices, which breaks later logic.~~                                                                                                                  | ~~Before `set_index`, do `df_scores = df_scores.drop_duplicates(subset=["Timestamp"])`. Optionally log if duplicates are found (`Console.warn`). Then set index.~~ **COMPLETED**                                                                                                                                                                                                |
| ~~FOR-COR-05~~    | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Correctness~~                 | ~~`should_retrain` + doc mismatch~~                                                                                                              | ~~Docstring says forecast error threshold is part of retrain logic, but current code only checks state existence, data hash change, drift and anomaly metrics.~~                                                                                                 | ~~Either integrate `compute_forecast_quality` to compare RMSE/MAE/MAPE to thresholds inside `should_retrain`, or update the docstring to reflect reality and ensure caller does the RMSE check explicitly. The goal: docs == code.~~ **COMPLETED**                                                                                                                              |
| ~~FOR-PERF-01~~   | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Performance~~                 | ~~Huge `IN` clause (your §3.1)~~                                                                                                                 | ~~Query builds `Timestamp IN (?, ?, ...)` with potentially thousands of timestamps, which leads to large queries and potential SQL performance issues.~~                                                                                                         | ~~Introduce batching or temp-table pattern: (1) bulk insert timestamps into a temp table, (2) join on that table. Or limit MAX IN clause size (e.g. 1000) and loop. Keep query semantics identical, just do it in batches.~~ **COMPLETED**                                                                                                                                      |
| ~~FOR-PERF-02~~   | ~~Low~~      | ~~`forecasting.py`~~                                                   | ~~Performance~~                 | ~~Repeated `fillna` loops (your §3.2, `merge_forecast_horizons`)~~                                                                               | ~~Logic repeatedly does `fillna(0)` per column in a loop. Works but can be vectorized.~~                                                                                                                                                                         | ~~Pre-fill as: `merged[[col_prev, col_new]] = merged[[col_prev, col_new]].fillna(0)`, then use `.values`. Same behaviour, less overhead. Do not change semantics (still 0 for missing).~~ **COMPLETED**                                                                                                                                                                         |
| ~~FOR-PERF-03~~   | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Performance / Design~~        | ~~`compute_data_hash` uses `df.to_csv` (your §3.3)~~                                                                                             | ~~Serializing entire DataFrame to CSV string to hash is expensive and CSV-centric.~~                                                                                                                                                                             | ~~Replace with deterministic binary hash: e.g., `vals = df[sorted(df.columns)].to_numpy(copy=False).tobytes(); schema = str(list(zip(df.columns, df.dtypes))).encode(); h = hashlib.sha256(vals + schema).hexdigest()[:16]`. This maintains "hash changes when data changes" semantics.~~ **COMPLETED**                                                                         |
| ~~FOR-PERF-04~~   | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Performance / Robustness~~    | ~~Large unbounded health timeline (your §3.4)~~                                                                                                  | ~~`df_health = rul_estimator._load_health_timeline(...)` can load huge windows (e.g., 72h at 1s sampling). No guard on row count.~~                                                                                                                              | ~~Enforce a max rows or max hours: e.g., if `len(df_health) > MAX_HEALTH_ROWS`, downsample (resample to 1min) before further processing. Expose these caps in config, but keep defaults conservative.~~ **COMPLETED**                                                                                                                                                           |
| ~~FOR-DQ-01~~     | ~~High~~     | ~~`forecasting.py`~~                                                   | ~~Data Quality~~                | ~~Input validation (your §4.1)~~                                                                                                                 | ~~`run_enhanced_forecasting_sql` accepts `sql_client: Any`, `equip_id: Optional[int]`, `run_id: Optional[str]` without validation, leading to subtle failures.~~                                                                                                 | ~~At the top of public entrypoints: validate inputs. Example: `if equip_id is None or equip_id < 0: raise ValueError(...)`. Same for `run_id` (non-empty string). This is defensive correctness, not new functionality.~~ **COMPLETED**                                                                                                                                         |
| ~~FOR-DQ-02~~     | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Data Quality~~                | ~~Scattered timezone handling (your §4.2)~~                                                                                                      | ~~Multiple ad-hoc blocks stripping timezone from timestamps; policy is duplicated and can diverge.~~                                                                                                                                                             | ~~Centralize timestamp normalization: add `normalize_timestamps(df, cols)` (already half-present as `_to_naive`) and use it everywhere. Document the rule: "all timestamps are stored as naive UTC". Apply consistently to both health and forecast horizons.~~ **COMPLETED**                                                                                                   |
| ~~FOR-DQ-03~~     | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Data Quality~~                | ~~Potential hazard/forecast length mismatch (your §4.3)~~                                                                                        | ~~Hazard computation builds `hazard_df` and aligns with forecast horizon but does not explicitly assert equal lengths. Misalignment could silently corrupt hazard data.~~                                                                                        | ~~After building both series: `assert len(hazard_df) == len(forecast_series), "Hazard/forecast length mismatch"`. If mismatch, log error and either truncate to min length or skip hazard write for that run.~~ **COMPLETED**                                                                                                                                                   |
| ~~FOR-CODE-01~~   | ~~Low~~      | ~~`forecasting.py`~~                                                   | ~~Code Health~~                 | ~~Magic numbers (your §5.1)~~                                                                                                                    | ~~Thresholds like 3, 20, 12.0 appear in multiple places (`MIN_AR1_SAMPLES`, min forecast samples, blend tau).~~                                                                                                                                                  | ~~Define module-level constants (`MIN_AR1_SAMPLES = 3`, `MIN_FORECAST_SAMPLES = 20`, `BLEND_TAU_HOURS = 12.0`). Replace literals with these constants and add a short comment about why these values exist (based on your domain choices).~~ **COMPLETED**                                                                                                                      |
| ~~FOR-CODE-02~~   | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Code Health~~                 | ~~Inconsistent error handling (your §5.2)~~                                                                                                      | ~~Mixture of silent returns, `Console.warn`, and hard exceptions makes it hard to reason about failure modes.~~                                                                                                                                                  | ~~Establish a simple convention: (1) non-fatal data conditions → `Console.warn` + safe fallback; (2) true configuration errors → raise `ValueError`; (3) unexpected SQL failures → `Console.error` + propagate or mark run failed. Apply this to key sections in `run_enhanced_forecasting_sql` and `should_retrain`.~~ **COMPLETED**                                           |
| ~~FOR-CODE-03~~   | ~~Low~~      | ~~`forecasting.py`~~                                                   | ~~Code Health~~                 | ~~Variable naming (`hi`, `ph`, `fp_df`, etc.) (your §5.3)~~                                                                                      | ~~Short names make code harder to maintain in complex logic.~~                                                                                                                                                                                                   | ~~Incrementally rename: `hi` → `health_series`, `ph` → `phi`, `fp_df` → `failure_prob_df`, etc. Use type hints to make meaning clear. No behaviour change.~~ **COMPLETED**                                                                                                                                                                                                      |
| ~~FOR-CODE-04~~   | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Code Health~~                 | ~~Type hints inconsistencies (your §5.4)~~                                                                                                       | ~~Some helpers have good type hints; key APIs like `run_enhanced_forecasting_sql` accept `sql_client: Any`.~~                                                                                                                                                    | ~~Introduce a `SqlClientProtocol` (or minimal Protocol) for the subset of methods used (`cursor()`, `execute`, etc.) and use that instead of `Any`. This is documentation + static safety, no runtime change.~~ **COMPLETED**                                                                                                                                                   |
| ~~FOR-AR1-01~~    | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Correctness~~                 | ~~`AR1Detector.score` data quality (your §8.1)~~                                                                                                 | ~~Currently silently imputes NaNs with `mu`, keeps some NaNs in residuals, and doesn't handle all-NaN columns explicitly.~~                                                                                                                                      | ~~Before scoring each column: if more than, say, 50% of values are NaN, log a warning and either mark that sensor as "unscorable" or drop it from AR1. For the rest, keep current imputation but log if imputation fraction is high. This keeps existing behaviour but surfaces data quality.~~ **COMPLETED**                                                                   |
| ~~FOR-MERGE-01~~  | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Correctness / Semantics~~     | ~~`merge_forecast_horizons` (your §8.2)~~                                                                                                        | ~~When previous and new horizons don't overlap, missing values are treated as 0 via `fillna(0)`, which is semantically "zero health", not "no forecast".~~                                                                                                       | ~~For merge semantics: use forward-fill or "prefer non-null" instead of filling with 0. E.g., `merged[col_new] = merged[col_new].fillna(merged[col_prev])` and only set to 0 where **both** are NaN. This retains information and avoids zeroing valid missing forecasts.~~ **COMPLETED**                                                                                       |
| ~~FOR-AR1-01~~    | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Correctness~~                 | ~~`AR1Detector.score` data quality (your §8.1)~~                                                                                                 | ~~Currently silently imputes NaNs with `mu`, keeps some NaNs in residuals, and doesn't handle all-NaN columns explicitly.~~                                                                                                                                      | ~~Before scoring each column: if more than, say, 50% of values are NaN, log a warning and either mark that sensor as "unscorable" or drop it from AR1. For the rest, keep current imputation but log if imputation fraction is high. This keeps existing behaviour but surfaces data quality.~~ **COMPLETED**                                                                   |
| ~~FOR-MERGE-01~~  | ~~Med~~      | ~~`forecasting.py`~~                                                   | ~~Correctness / Semantics~~     | ~~`merge_forecast_horizons` (your §8.2)~~                                                                                                        | ~~When previous and new horizons don't overlap, missing values are treated as 0 via `fillna(0)`, which is semantically "zero health", not "no forecast".~~                                                                                                       | ~~For merge semantics: use forward-fill or "prefer non-null" instead of filling with 0. E.g., `merged[col_new] = merged[col_new].fillna(merged[col_prev])` and only set to 0 where **both** are NaN. This retains information and avoids zeroing valid missing forecasts.~~ **COMPLETED**                                                                                       |
| FOR-DESIGN-01 | Med      | `forecasting.py`                                                   | Design                      | God-function `run_enhanced_forecasting_sql` (your §2.2)                                                                                      | Very long function doing: data loading, state mgmt, forecasting, causation, maintenance, persistence. Hard to test and reason about.                                                                                                                         | Split into internal helpers: `_load_forecast_inputs`, `_load_prev_state`, `_compute_forecast`, `_compute_failure_hazard`, `_prepare_outputs`, `_persist_outputs`. Keep signatures and behaviour identical, just move blocks into separate functions. No new features.                                                                                         |
| FOR-DESIGN-02 | Med      | `forecasting.py`                                                   | Design                      | Tight coupling to `sql_client` (your §2.1, 6.1)                                                                                              | Functions like `should_retrain` directly construct SQL, run queries, and interpret rows. Hard to test and mock.                                                                                                                                              | Introduce a small repository interface (even if just a class with concrete methods): `ForecastRepository` with methods `get_recent_drift`, `get_anomaly_energy`, `get_health_timeline`. Implement this on top of `sql_client` and pass it into `should_retrain` / `run_enhanced_forecasting_sql`. Keep SQL semantics identical; this just isolates DB access. |
| ~~RUL-CSV-01~~    | ~~Med~~      | ~~`rul_estimator.py`~~                                                 | ~~SQL Migration~~               | ~~CSV health timeline loader~~                                                                                                                   | ~~CSV-based load path exists as fallback for RUL.~~                                                                                                                                                                                                              | ~~For production: ensure RUL uses only SQL (`ACM_HealthTimeline`) via `sql_client`. Move CSV loader into dev-only branch or remove once unused. Behaviour of "what data is loaded" stays the same, only source changes.~~ **COMPLETED**                                                                                                                                         |
| ~~RUL-CSV-02~~    | ~~Med~~      | ~~`enhanced_rul_estimator.py`~~                                        | ~~SQL Migration~~               | ~~CSV health timeline loader~~                                                                                                                   | ~~Same as above.~~                                                                                                                                                                                                                                               | ~~Same action as RUL-CSV-01, but ensure both simple and enhanced RUL use a **single** SQL-backed loader from `rul_common.py`.~~ **COMPLETED**                                                                                                                                                                                                                   |
| RUL-COR-01    | Med      | `rul_common.py` + `rul_estimator.py` + `enhanced_rul_estimator.py` | Correctness / Duplication   | Shared helpers (health loader, attribution builders) are duplicated and partially call each other across modules.                            | Move all shared helpers into `rul_common.py`. Refactor both RUL modules to import from there. That reduces duplication and risk of subtle drift between simple/enhanced paths.                                                                               |                                                                                                                                                                                                                                                                                                                                                               |
| ~~RM-COR-01~~     | ~~Low~~      | ~~`run_metadata_writer.py`~~                                           | ~~Correctness / Transparency~~  | ~~`extract_data_quality_score` expects certain score/data-quality columns; schema changes may silently reduce coverage.~~                        | ~~Add a small schema check: log which expected columns are missing and how the data quality score is affected. This is about visibility, not altering scoring formula.~~ **COMPLETED**                                                                                         |                                                                                                                                                                                                                                                                                                                                                               |
| ~~MP-COR-01~~ | ~~Low~~      | ~~`model_persistence.py`~~                                             | ~~Correctness / Observability~~ | ~~`ModelVersionManager.get_latest_version` silently ignores malformed directories under `models_root` (e.g., `vX`), which could hide mistakes.~~ | ~~When scanning directories: log a debug/warn message for any folder not matching `^v\d+$`. This helps detect corrupt model folders.~~ **COMPLETED**                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                               |
| ~~MP-COR-02~~     | ~~Low~~      | ~~`model_persistence.py`~~                                             | ~~Code Health~~                 | ~~`create_model_metadata` contains fields (`model_params`, `residual_variance`) that are always empty in callers.~~                              | ~~Either mark these fields as deprecated in docstring and keep them empty, or remove them from the dataclass/schema and SQL. This reduces confusion: metadata only contains what you actually use (train window, detectors present, config signature, hashes).~~ **COMPLETED** |                                                                                                                                                                                                                                                                                                                                                               |


