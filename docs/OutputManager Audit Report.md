# OutputManager Audit Report

## Critical Issues

| Task ID | Where is the Fault | What is Wrong | What to Fix | How to Fix | Impact of Correctness | Severity/Urgency |
|---------|-------------------|---------------|-------------|------------|----------------------|------------------|
| CRIT-01 | `_bulk_insert_sql()` lines 878-920 | DELETE before INSERT logic commented out but referenced in docstring. Leaves stale data and causes PK violations for tables with (RunID, EquipID) keys | Remove misleading comments about upsert pattern or restore the DELETE logic | Uncomment DELETE section or remove the NOTE comment block entirely to avoid confusion | Prevents duplicate data accumulation across runs; ensures data integrity | **CRITICAL** - Data corruption |
| CRIT-02 | `write_table()` line 737 | Calls `_upsert_pca_metrics()` for ACM_PCA_Metrics but this table requires composite PK (RunID, EquipID, ComponentName, MetricType) per SQL schema | Change upsert key logic to match actual schema | Use all 4 PK columns in DELETE WHERE clause: `RunID = ? AND EquipID = ? AND ComponentName = ? AND MetricType = ?` | Prevents PK violations and allows incremental metric updates | **CRITICAL** - Runtime failures |
| CRIT-03 | `_upsert_pca_metrics()` lines 1320-1371 | Only deletes by (RunID, EquipID) but PK also includes ComponentName and MetricType. Will delete all metrics for equipment when updating a single metric | Fix DELETE scope to match full PK | Add ComponentName and MetricType to WHERE clause or use MERGE upsert like other forecast tables | Prevents accidental deletion of unrelated metrics | **HIGH** - Data loss risk |
| CRIT-04 | `_apply_sql_required_defaults()` lines 839-868 | Uses sentinel timestamp `1900-01-01 00:00:00` for missing NOT NULL timestamp columns. SQL Server may reject this as invalid or it may cause filtering issues | Use `pd.Timestamp.now()` or explicit NULL handling | Replace `sentinel_ts = pd.Timestamp(year=1900, month=1, day=1)` with `sentinel_ts = pd.Timestamp.now()` | Ensures valid timestamps; prevents query failures due to date range constraints | **HIGH** - Data validity |
| CRIT-05 | `write_threshold_metadata()` lines 2469-2539 | Calls `self.sql_client.cursor()` but also uses `self.sql_client.get_cursor()` in read method. Inconsistent API usage; may fail if client doesn't support both patterns | Standardize cursor acquisition | Use consistent pattern throughout - prefer `with self.sql_client.cursor() as cur:` | Prevents runtime errors; ensures proper cursor cleanup | **HIGH** - Runtime failures |
| CRIT-06 | `_bulk_insert_sql()` lines 976-979 | Replaces extreme float values `> 1e100` with None but threshold is too high - SQL Server FLOAT max is ~1.7e308 but practical safe range is much smaller | Lower threshold to `1e38` (SQL Server DECIMAL max) | Change condition to `if abs_mask.any() and df_clean[col].abs().max() > 1e38:` | Prevents arithmetic overflow errors in SQL Server | **HIGH** - Data loss/errors |

## High-Priority Issues

| Task ID | Where is the Fault | What is Wrong | What to Fix | How to Fix | Impact of Correctness | Severity/Urgency |
|---------|-------------------|---------------|-------------|------------|----------------------|------------------|
| HIGH-01 | `_generate_defect_timeline()` lines 1869-1920 | Uses `zones.shift()` result (`zones_shifted`) directly without checking for empty result at index 0 | Add bounds checking | Check if idx is first index before accessing shifted value: `from_zone = 'START' if idx == scores_df.index[0] else str(zones_shifted.loc[idx])` | Prevents KeyError on first timestamp; ensures complete timeline | **HIGH** - Missing data |
| HIGH-02 | `_bulk_insert_sql()` lines 949-985 | Comment says "Delete before INSERT removed" but RUL-UPSERT section at lines 1003-1020 still performs DELETE. Inconsistent behavior across tables | Standardize upsert strategy | Apply DELETE-then-INSERT to ALL tables or use MERGE for ALL tables; document decision | Ensures predictable behavior; prevents confusion | **HIGH** - Inconsistency |
| HIGH-03 | `_generate_episode_severity_mapping()` lines 1772-1812 | Returns dict with severity counts but doesn't validate that sum matches total_episodes. Sets validation_status but never acts on mismatch | Add validation enforcement | Raise warning if `count_sum != total_episodes`: `if validation_status == "MISMATCH": Console.warn(f"Severity counts mismatch: {count_sum} != {total_episodes}")` | Catches data quality issues early; alerts to processing errors | **MEDIUM** - QA |
| HIGH-04 | `write_episodes()` lines 1612-1680 | Writes to both `ACM_EpisodeDiagnostics` (detail) and `ACM_Episodes` (summary) but uses different schemas. If summary write fails, detail is already committed | Use transaction for related writes | Wrap both writes in `with self.batched_transaction():` block | Ensures atomicity; prevents partial state | **MEDIUM** - Data integrity |
| HIGH-05 | `_generate_sensor_hotspots_table()` lines 2146-2227 | Accesses `sensor_values.loc[max_idx, sensor]` without checking if max_idx exists in sensor_values index | Add index validation | Check if `max_idx in sensor_values.index` before accessing: `if max_idx in sensor_values.index: value_at_peak = sensor_values.loc[max_idx, sensor]` | Prevents KeyError when indices don't align; ensures robustness | **MEDIUM** - Runtime errors |
| HIGH-06 | `_generate_regime_occupancy()` lines 2098-2140 | Attempts to convert `regime_label` to Int64 but doesn't handle case where all values are NaN after coercion | Add empty result handling | After `regimes = pd.to_numeric(...).dropna().astype('Int64')`, add: `if regimes.empty: return pd.DataFrame(...)` (already present, good) | Already handled correctly - no action needed | **INFO** - Already correct |

## Medium-Priority Issues

| Task ID | Where is the Fault | What is Wrong | What to Fix | How to Fix | Impact of Correctness | Severity/Urgency |
|---------|-------------------|---------------|-------------|------------|----------------------|------------------|
| MED-01 | `_prepare_dataframe_for_sql()` lines 668-702 | Converts boolean to int via `astype(object).where().astype(int)` - complex chain that may fail on mixed types | Simplify boolean conversion | Use direct conversion: `out[col] = out[col].astype(int)` with try/except | More reliable type coercion; clearer code | **MEDIUM** - Robustness |
| MED-02 | `write_dataframe()` lines 752-828 | Calls `_apply_sql_required_defaults()` but ignores returned `repair_info` except for allow_repair check. Doesn't log what was repaired | Add repair logging | After repair, log: `if repair_info['repairs_needed']: Console.debug(f"Applied defaults to {sql_table}: {repair_info['missing_fields']}")` | Better observability; aids debugging | **LOW** - Debugging |
| MED-03 | `_generate_culprit_history()` - **MISSING** | Referenced in comprehensive analytics at line 2030 but method not defined in class | Implement missing method | Add `_generate_culprit_history(self, scores_df, episodes_df)` method that extracts culprit sensors from episodes | Completes analytics suite; prevents runtime errors | **HIGH** - Missing feature |
| MED-04 | `_generate_episode_metrics()` - **MISSING** | Referenced in comprehensive analytics at line 2037 but method not defined in class | Implement missing method | Add `_generate_episode_metrics(self, episodes_df)` method that calculates episode statistics | Completes analytics suite; prevents runtime errors | **HIGH** - Missing feature |
| MED-05 | `_generate_episode_diagnostics()` - **MISSING** | Referenced in comprehensive analytics at line 2044 but method not defined in class | Implement missing method | Add `_generate_episode_diagnostics(self, episodes_df, scores_df)` method that generates per-episode diagnostics | Completes analytics suite; prevents runtime errors | **HIGH** - Missing feature |
| MED-06 | `_generate_omr_contributions_long()` - **MISSING** | Referenced at line 1752 but method not defined in class | Implement missing method | Add `_generate_omr_contributions_long(self, scores_df, omr_contributions)` method that melts OMR data to long format | Enables OMR sensor analysis; prevents runtime errors | **HIGH** - Missing feature |
| MED-07 | `_generate_regime_stats()` - **MISSING** | Referenced at line 1772 but method not defined in class | Implement missing method | Add `_generate_regime_stats(self, scores_df)` method that computes compact regime statistics | Completes regime analytics; prevents runtime errors | **MEDIUM** - Missing feature |
| MED-08 | `_generate_daily_fused_profile()` - **MISSING** | Referenced at line 1805 but method not defined in class | Implement missing method | Add `_generate_daily_fused_profile(self, scores_df)` method that aggregates health by hour Ã— day-of-week | Enables temporal pattern analysis; prevents runtime errors | **MEDIUM** - Missing feature |
| MED-09 | `generate_all_analytics_tables()` lines 1672-2068 | Calls 8 methods that are not defined in the class (see MED-03 through MED-08). Will raise AttributeError at runtime | Implement all missing generator methods | Add all 8 missing methods following the pattern of existing generators | Completes analytics feature set; prevents runtime failures | **CRITICAL** - Missing implementation |

## Low-Priority Issues

| Task ID | Where is the Fault | What is Wrong | What to Fix | How to Fix | Impact of Correctness | Severity/Urgency |
|---------|-------------------|---------------|-------------|------------|----------------------|------------------|
| LOW-01 | `_check_sql_health()` lines 637-666 | Uses nested try/finally but doesn't handle case where cursor creation itself fails | Add cursor creation guard | Wrap `cur = self.sql_client.cursor()` in separate try/except before main try block | More robust error handling | **LOW** - Edge case |
| LOW-02 | `write_scores()` lines 1581-1610 | Hardcodes column mapping dict - if scores schema changes, this becomes stale | Make column mapping configurable | Move `score_columns` dict to class constant or config parameter | Easier maintenance; prevents schema drift | **LOW** - Maintainability |
| LOW-03 | `_generate_health_histogram()` - **MISSING** | Referenced at line 1792 but method not defined in class | Implement missing method | Add `_generate_health_histogram(self, scores_df)` method that bins health index into 10-point buckets | Completes health analytics; prevents runtime errors | **MEDIUM** - Missing feature |
| LOW-04 | `_generate_alert_age()` - **MISSING** | Referenced at line 1800 but method not defined in class | Implement missing method | Add `_generate_alert_age(self, scores_df)` method that calculates time since first alert | Completes alert analytics; prevents runtime errors | **MEDIUM** - Missing feature |
| LOW-05 | `_generate_regime_stability()` - **MISSING** | Referenced at line 1812 but method not defined in class | Implement missing method | Add `_generate_regime_stability(self, scores_df)` method that measures regime transition frequency | Completes regime analytics; prevents runtime errors | **MEDIUM** - Missing feature |
| LOW-06 | `close()` method line 2080 | Swallows all exceptions with bare `except:` - makes debugging difficult | Add exception logging | Change to: `except Exception as e: Console.warn(f"Error during close: {e}")` | Better error visibility | **LOW** - Debugging |
| LOW-07 | `_should_auto_flush()` lines 708-721 | Uses time-based flush but doesn't consider timezone issues across runs | Use timezone-aware comparison | Store `created_at` as timezone-aware timestamp: `field(default_factory=lambda: time.time())` is OK, but document timezone assumption | Prevents flush timing bugs in distributed systems | **LOW** - Edge case |
| LOW-08 | `get_stats()` lines 2069-2077 | Division by zero risk if `files_written` or `sql_health_checks` is 0 | Add zero checks | Already uses `max(1, ...)` pattern - no fix needed | Already handled correctly | **INFO** - Already correct |

## Documentation/Consistency Issues

| Task ID | Where is the Fault | What is Wrong | What to Fix | How to Fix | Impact of Correctness | Severity/Urgency |
|---------|-------------------|---------------|-------------|------------|----------------------|------------------|
| DOC-01 | Class docstring lines 573-586 | Claims to replace "scattered to_csv() calls" but file writes are disabled in `sql_only_mode` | Update docstring | Change to: "Unified output manager for SQL-first ACM analytics. File writes optional via `sql_only_mode=False`" | Accurate documentation; prevents confusion | **LOW** - Documentation |
| DOC-02 | `write_dataframe()` docstring lines 752-768 | Says "Write DataFrame to SQL (file output disabled)" but method still accepts CSV-related kwargs | Remove stale parameters | Remove `**csv_kwargs` from signature or document that they're ignored | Clearer API contract | **LOW** - Documentation |
| DOC-03 | `load_data()` lines 468-471 | Parameter `equipment_name` has example values `'FD_FAN', 'GAS_TURBINE'` but no validation that these are valid equipment names | Add validation or enum | Add config-based validation: `if equipment_name not in cfg.get('valid_equipment', []): raise ValueError(...)` | Prevents typos; earlier error detection | **LOW** - Validation |
| DOC-04 | `ALLOWED_TABLES` constant lines 44-74 | Contains 60+ table names but no documentation of schema requirements per table | Add schema reference | Add comment: `# Schema reference: see docs/sql_schema.md or ACM database documentation` | Easier maintenance; clearer expectations | **LOW** - Documentation |
| DOC-05 | `_sql_required_defaults` dict lines 636-658 | Contains defaults for 40+ tables but many entries have outdated column names (e.g., `CiLower` vs `CI_Lower`) | Audit column names | Cross-reference with actual SQL schema and update mismatches | Prevents schema drift; ensures defaults work | **MEDIUM** - Schema alignment |

## Architecture/Design Issues

| Task ID | Where is the Fault | What is Wrong | What to Fix | How to Fix | Impact of Correctness | Severity/Urgency |
|---------|-------------------|---------------|-------------|------------|----------------------|------------------|
| ARCH-01 | Overall class design | OutputManager has grown to 2500+ lines with 50+ methods - violates single responsibility principle | Refactor into multiple classes | Split into: `SQLWriter`, `AnalyticsGenerator`, `DataLoader`, `ArtifactCache` classes with OutputManager as facade | Better maintainability; easier testing | **MEDIUM** - Technical debt |
| ARCH-02 | `generate_all_analytics_tables()` lines 1672-2068 | 400-line method with 26 table generators - hard to test and debug | Break into smaller methods | Split into: `_generate_tier_a_tables()`, `_generate_tier_b_tables()`, `_generate_tier_c_tables()` | Easier testing; better error isolation | **MEDIUM** - Technical debt |
| ARCH-03 | Caching strategy lines 626-630 | Uses 4 separate cache dicts (`_table_exists_cache`, `_table_columns_cache`, etc.) - inefficient and error-prone | Consolidate caching | Use single cache with composite keys: `_cache = {(table_name, 'exists'): bool, (table_name, 'columns'): set}` | Simpler cache management; less memory | **LOW** - Optimization |
| ARCH-04 | Transaction management | Mixes explicit commits with `batched_transaction()` context manager - confusing control flow | Standardize transaction pattern | Always use `batched_transaction()` for multi-table writes; document commit behavior | Clearer transaction boundaries; prevents commit bugs | **MEDIUM** - Consistency |
| ARCH-05 | Error handling | Inconsistent patterns - some methods raise exceptions, others return 0/None/empty DataFrames | Standardize error handling | Define error handling policy: analytics methods return empty DataFrames, SQL methods raise exceptions | Predictable error propagation | **LOW** - Consistency |

## Summary Statistics

- **Critical Issues**: 6 (immediate data integrity/runtime failures)
- **High-Priority Issues**: 6 (missing methods, validation gaps)
- **Medium-Priority Issues**: 9 (missing features, robustness improvements)
- **Low-Priority Issues**: 8 (edge cases, documentation)
- **Architecture Issues**: 5 (technical debt, design improvements)

**Most Urgent**: 
1. Implement 8 missing generator methods (MED-03 through MED-09, LOW-03 through LOW-05)
2. Fix PK violation in `_upsert_pca_metrics()` (CRIT-02, CRIT-03)
3. Fix DELETE-before-INSERT inconsistency (CRIT-01, HIGH-02)