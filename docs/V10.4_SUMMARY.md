# v10.4.0 Implementation Summary

**Status**: In Progress (3 of 8 phases complete)  
**Date**: 2025-12-23

---

## Executive Summary

v10.4.0 is a **tactical release** to fix critical stability issues in ACM v10.3.0 identified during v11 planning. The goal is to make ACM more honest, reliable, and better prepared for the full v11 architectural refactor.

**Key Philosophy**: "Amputate, don't fix" - Remove broken features rather than attempting complex mid-way fixes.

---

## Completed Phases

### ✅ Phase 1: UNKNOWN Regime Support

**Problem**: System forced nearest-regime assignment even with low confidence, violating v11 Rule #4.

**Solution**:
- Added `REGIME_UNKNOWN = -1` constant for low-confidence states
- Added `regimes.assignment.min_confidence` config parameter (default: 0.0 = disabled)
- Modified `predict_regime()` to compute confidence from distance to nearest cluster
- Confidence = 1.0 / (1.0 + normalized_distance_to_nearest)
- When confidence < threshold, assigns -1 (UNKNOWN) instead of forcing

**Files Changed**:
- `core/regimes.py` (90 lines changed)
- `utils/version.py` (version bump)
- `docs/V10.4_PLAN.md` (new)

**Impact**: ACM can now say "I don't know" instead of making up an answer.

---

### ✅ Phase 2: RUL Reliability Gating

**Problem**: System wrote numeric RUL predictions even when prerequisites failed, violating v11 Rule #7.

**Solution**:
- Added `RULStatus` enum: RELIABLE, NOT_RELIABLE, INSUFFICIENT_DATA
- Added `status` and `status_reason` fields to `RULEstimate` dataclass
- Implemented `check_prerequisites()` with 4 validation checks:
  1. Data quality must be OK or GAPPY (not SPARSE/FLAT/NOISY)
  2. Regime must be stable (not UNKNOWN, confidence > 0.6)
  3. Persistent degradation (slope < 0 for >= 3 batches)
  4. Low drift (drift_level < 0.5)
- Modified `estimate_rul()` to check prerequisites BEFORE computing
- Returns NaN values when status is NOT_RELIABLE or INSUFFICIENT_DATA

**Files Changed**:
- `core/rul_estimator.py` (166 lines changed)

**Impact**: No more misleading RUL predictions on healthy or unstable equipment.

---

### ✅ Phase 3: Data Contract Validation

**Problem**: No validation at pipeline entry, garbage data corrupted analytics, violating v11 Requirement #9.

**Solution**:
- Created `DataContract` class with 4 validation rules:
  1. **Timestamp Order**: Monotonic increasing (no backward jumps)
  2. **No Duplicates**: Unique timestamps
  3. **No Future Rows**: Timestamps <= now + tolerance (default: 24h)
  4. **Cadence**: Median gap within [60s, 3600s] range
- Created `ContractViolation` exception for fatal errors
- Created `ValidationResult` dataclass for detailed feedback
- Configurable thresholds and strict/permissive modes

**Files Changed**:
- `core/data_contract.py` (new, 347 lines)

**Impact**: Bad data rejected at pipeline entry with clear error messages.

---

## Remaining Phases

### ⏳ Phase 4: Wire Data Contract into ACM Main

**Goal**: Integrate data contract validation into the main pipeline.

**Tasks**:
- [ ] Add validation call at pipeline entry in `acm_main.py`
- [ ] Handle violations gracefully (return NOOP with clear error)
- [ ] Add config flag `data_contract.strict` (default: true)
- [ ] Test with good/bad data

**Estimated Effort**: 1 hour

---

### ⏳ Phase 5: Disable Point-Anomaly Alerts

**Goal**: Make episodes the only alerting primitive (v11 Rule #7).

**Tasks**:
- [ ] Add config flag `episodes_only_alerts` (default: true)
- [ ] Disable point-anomaly alert logic in `acm_main.py`
- [ ] Ensure episode detection still runs
- [ ] Document that point alerts are deprecated

**Estimated Effort**: 1 hour

---

### ⏳ Phase 6: Detector Train-Score Separation

**Goal**: Ensure current batch cannot influence its own anomaly scores (v11 Rule #8).

**Tasks**:
- [ ] Audit each detector's `fit()` and `score()` methods:
  - AR1 (`core/ar1_detector.py`)
  - PCA (`core/outliers.py`)
  - IForest (`core/outliers.py`)
  - GMM (`core/outliers.py`)
  - OMR (`core/omr.py`)
- [ ] Add explicit guards: training data != scoring data
- [ ] Document separation contract in docstrings
- [ ] Add assertion checks in development mode

**Known Issues**:
- AR1: Currently fits on full window including current batch
- PCA: Uses sliding window that includes current batch

**Estimated Effort**: 3-4 hours

---

### ⏳ Phase 7: Consolidate Forecasting

**Goal**: Remove duplicate forecasting logic, single source of truth.

**Tasks**:
- [ ] Verify all forecasting routes through `ForecastEngine`
- [ ] Remove duplicate SQL write paths
- [ ] Add deprecation warnings to legacy modules
- [ ] Update documentation to reference only ForecastEngine

**Files to Update**:
- `forecasting_legacy.py` (mark deprecated)
- `rul_engine_legacy.py` (mark deprecated)
- `core/forecast_engine.py` (verify as primary)

**Estimated Effort**: 1 hour

---

### ⏳ Phase 8: Testing & Validation

**Goal**: Verify no regressions, all features work as expected.

**Tasks**:
- [ ] Run batch tests on 2 equipment (FD_FAN, GAS_TURBINE)
- [ ] Verify UNKNOWN regimes appear correctly
- [ ] Verify RUL NOT_RELIABLE status works
- [ ] Verify data contract rejects bad data
- [ ] Verify no regressions in core analytics
- [ ] Update Grafana dashboards if needed

**Estimated Effort**: 2 hours

---

## Success Criteria

**v10.4.0 is successful when:**

1. ✅ System can output "UNKNOWN" regime (no forced assignment)
2. ✅ RUL includes reliability status (no misleading predictions)
3. ✅ Data contract validation implemented (ready to wire)
4. ⏳ Data contract wired into pipeline (Phase 4)
5. ⏳ Point-anomaly alerts disabled (Phase 5)
6. ⏳ Detectors enforce train-score separation (Phase 6)
7. ⏳ Forecasting consolidated (Phase 7)
8. ⏳ All existing tests pass (Phase 8)
9. ⏳ No regressions in core analytics (Phase 8)
10. ⏳ Documentation updated (Phase 8)

---

## What's Deferred to v11

The following v11 requirements are **NOT** addressed in v10.4:

- **Online/Offline Mode Split** (v11 Item #1) - Too invasive
- **ACM_ActiveModels Pointer** (v11 Item #2) - Requires new table
- **Maturity State Gating** (v11 Item #13) - Complex state machine
- **Offline Historical Replay** (v11 Item #14) - New runner script
- **Unified Baseline Normalization** (v11 Item #20) - Cross-module refactor
- **Calibrated Fusion** (v11 Item #22) - Algorithm change
- **Drift/Novelty Control Plane** (v11 Item #10) - New subsystem
- **Episode-Only Alerting** (v11 Item #6) - Partially done (disable points only)

These require the full v11 architectural refactor (50+ items across 5 phases).

---

## Timeline

- **Phases 1-3** (UNKNOWN, RUL gating, Data contracts): ✅ **3 hours** (DONE)
- **Phase 4** (Wire data contract): ⏳ 1 hour
- **Phase 5** (Disable point alerts): ⏳ 1 hour
- **Phase 6** (Train-score separation): ⏳ 3-4 hours
- **Phase 7** (Consolidate forecasting): ⏳ 1 hour
- **Phase 8** (Testing): ⏳ 2 hours

**Total Estimated**: 11-14 hours  
**Completed**: 3 hours (21%)  
**Remaining**: 8-11 hours (79%)

---

## Breaking Changes

**v10.4.0 is BACKWARD COMPATIBLE with v10.3.0**:

- New features are opt-in via config flags
- Default behavior preserves v10.3.0 semantics
- New dataclass fields are additions (not replacements)
- No SQL schema changes required
- No database migrations needed

**To enable v10.4 features:**
1. Set `regimes.assignment.min_confidence = 0.5` for UNKNOWN regime detection
2. Set `data_contract.strict = true` to enable validation (future phase)
3. Pass prerequisite parameters to `estimate_rul()` for reliability gating

---

## Rollback Plan

If v10.4.0 causes issues:

1. Revert to v10.3.0 tag: `git checkout v10.3.0`
2. Redeploy previous version
3. Set all v10.4 config flags to disabled/default values
4. No database changes needed (backward compatible)

---

## Next Actions

**Immediate** (complete v10.4.0):
1. Complete Phase 4 (wire data contract)
2. Complete Phase 5 (disable point alerts)
3. Complete Phase 6 (train-score separation)
4. Complete Phase 7 (consolidate forecasting)
5. Complete Phase 8 (testing)
6. Tag release as v10.4.0

**Short-term** (prepare for v11):
1. Gather operator feedback on UNKNOWN regimes
2. Tune reliability gates based on real-world data
3. Monitor data contract rejection rates
4. Document lessons learned for v11 planning
5. Create detailed v11 implementation tracker

**Long-term** (v11.0.0):
1. Execute full architectural refactor (50+ items)
2. Implement online/offline mode split
3. Implement regime versioning and maturity states
4. Implement drift/novelty control plane
5. Implement calibrated fusion
6. Comprehensive regression testing

---

## Conclusion

v10.4.0 delivers **critical stability improvements** without attempting the full v11 refactor:

- **More honest**: Can say "UNKNOWN" instead of guessing
- **More reliable**: Gates unreliable RUL predictions
- **More defensive**: Rejects corrupt data at entry point

This creates **breathing room** to execute v11 properly, without rushing into a complex architectural change while v10.3 is unstable.

Key principle: **Remove broken features rather than trying to fix them halfway**.

The full v11 refactor (with 50+ items across 5 phases) remains the long-term goal.
